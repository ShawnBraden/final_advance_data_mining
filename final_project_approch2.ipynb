{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548b4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from community import community_louvain\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4191303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories = pd.read_csv('inventories.csv')\n",
    "inventory_parts = pd.read_csv('inventory_parts.csv')\n",
    "inventory_sets = pd.read_csv('inventory_sets.csv')\n",
    "part_categories = pd.read_csv('part_categories.csv')\n",
    "parts = pd.read_csv('parts.csv')\n",
    "sets = pd.read_csv('sets.csv')\n",
    "themes = pd.read_csv('themes.csv')\n",
    "colors = pd.read_csv('colors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99588c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# Merge datasets to get set metadata\n",
    "sets_themes = sets.merge(themes, left_on='theme_id', right_on='id', suffixes=('_set', '_theme'))\n",
    "sets_themes = sets_themes.rename(columns={'id': 'theme_id_actual'})\n",
    "\n",
    "# Link inventories to sets (use latest version)\n",
    "inventories = inventories.sort_values('version').drop_duplicates('set_num', keep='last')\n",
    "sets_inventories = sets_themes.merge(inventories, on='set_num', how='left')\n",
    "\n",
    "# Merge with inventory_parts to get part details\n",
    "set_parts = sets_inventories.merge(inventory_parts, left_on='id', right_on='inventory_id', how='left')\n",
    "set_parts = set_parts.merge(parts, on='part_num', how='left')\n",
    "set_parts = set_parts.merge(part_categories, left_on='part_cat_id', right_on='id', suffixes=('_part', '_cat'))\n",
    "set_parts = set_parts.merge(colors, left_on='color_id', right_on='id', suffixes=('_part', '_color'))\n",
    "\n",
    "# Filter out sets with no part data\n",
    "valid_sets = set_parts[set_parts['part_num'].notnull()]['set_num'].unique()\n",
    "set_parts = set_parts[set_parts['set_num'].isin(valid_sets)]\n",
    "sets_inventories = sets_inventories[sets_inventories['set_num'].isin(valid_sets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a311eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build Global Part Graph\n",
    "def build_part_graph(set_parts):\n",
    "    G = nx.Graph()\n",
    "    unique_parts = set_parts['part_num'].unique()\n",
    "    for part in unique_parts:\n",
    "        G.add_node(part)\n",
    "    \n",
    "    set_groups = set_parts.groupby('set_num')['part_num'].apply(list)\n",
    "    for parts in set_groups:\n",
    "        for part1, part2 in combinations(parts, 2):\n",
    "            if G.has_edge(part1, part2):\n",
    "                G[part1][part2]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(part1, part2, weight=1)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358fe28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Part Graph: 23113 nodes, 3821261 edges\n"
     ]
    }
   ],
   "source": [
    "part_graph = build_part_graph(set_parts)\n",
    "print(f\"\\nGlobal Part Graph: {part_graph.number_of_nodes()} nodes, {part_graph.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0141bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Global Part Graph Community Detection\n",
    "def get_node2vec_embeddings(graph, dimensions=32, walk_length=30, num_walks=200, p=1, q=1):\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        return {}\n",
    "    try:\n",
    "        node2vec = Node2Vec(\n",
    "            graph,\n",
    "            dimensions=dimensions,\n",
    "            walk_length=walk_length,\n",
    "            num_walks=num_walks,\n",
    "            p=p,\n",
    "            q=q,\n",
    "            workers=1,\n",
    "            quiet=True\n",
    "        )\n",
    "        model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "        return {node: model.wv[str(node)] for node in graph.nodes}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4512019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Louvain Communities:\n",
      "  part_num  community\n",
      "0    29c01          0\n",
      "1    3001a          0\n",
      "2    3002a          0\n",
      "3     3003          0\n",
      "4     3004          0\n"
     ]
    }
   ],
   "source": [
    "# Louvain Community Detection\n",
    "try:\n",
    "    partition = community_louvain.best_partition(part_graph, weight='weight')\n",
    "    part_communities = pd.DataFrame({\n",
    "        'part_num': list(partition.keys()),\n",
    "        'community': list(partition.values())\n",
    "    })\n",
    "    print(\"\\nLouvain Communities:\")\n",
    "    print(part_communities.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error in Louvain community detection: {e}\")\n",
    "    part_communities = pd.DataFrame({'part_num': [], 'community': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2da6698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "part_num",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "community",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "55c0388e-4ebc-4b71-82e9-cc9a15353066",
       "rows": [
        [
         "0",
         "29c01",
         "0"
        ],
        [
         "1",
         "3001a",
         "0"
        ],
        [
         "2",
         "3002a",
         "0"
        ],
        [
         "3",
         "3003",
         "0"
        ],
        [
         "4",
         "3004",
         "0"
        ],
        [
         "5",
         "3005",
         "0"
        ],
        [
         "6",
         "3006",
         "0"
        ],
        [
         "7",
         "3007",
         "0"
        ],
        [
         "8",
         "3008",
         "0"
        ],
        [
         "9",
         "3009",
         "0"
        ],
        [
         "10",
         "3010",
         "0"
        ],
        [
         "11",
         "3020",
         "0"
        ],
        [
         "12",
         "3021",
         "0"
        ],
        [
         "13",
         "3022",
         "0"
        ],
        [
         "14",
         "3028",
         "0"
        ],
        [
         "15",
         "3032",
         "0"
        ],
        [
         "16",
         "3035",
         "0"
        ],
        [
         "17",
         "3036",
         "0"
        ],
        [
         "18",
         "3038",
         "0"
        ],
        [
         "19",
         "3039",
         "0"
        ],
        [
         "20",
         "3043",
         "0"
        ],
        [
         "21",
         "3045",
         "0"
        ],
        [
         "22",
         "3062a",
         "0"
        ],
        [
         "23",
         "3081cc01",
         "0"
        ],
        [
         "24",
         "700ed",
         "0"
        ],
        [
         "25",
         "777px8",
         "0"
        ],
        [
         "26",
         "3624",
         "0"
        ],
        [
         "27",
         "3625",
         "0"
        ],
        [
         "28",
         "3626apr0001",
         "0"
        ],
        [
         "29",
         "3833",
         "0"
        ],
        [
         "30",
         "970c00",
         "0"
        ],
        [
         "31",
         "973c02",
         "0"
        ],
        [
         "32",
         "973c07",
         "0"
        ],
        [
         "33",
         "973pb0091c01",
         "0"
        ],
        [
         "34",
         "3838",
         "0"
        ],
        [
         "35",
         "3842a",
         "0"
        ],
        [
         "36",
         "3962a",
         "0"
        ],
        [
         "37",
         "973p90c02",
         "0"
        ],
        [
         "38",
         "973p90c05",
         "0"
        ],
        [
         "39",
         "973p90c04",
         "0"
        ],
        [
         "40",
         "3844",
         "0"
        ],
        [
         "41",
         "3847a",
         "0"
        ],
        [
         "42",
         "970x021",
         "0"
        ],
        [
         "43",
         "970x026",
         "0"
        ],
        [
         "44",
         "973p47c01",
         "0"
        ],
        [
         "45",
         "973px45c01",
         "0"
        ],
        [
         "46",
         "973px47c01",
         "0"
        ],
        [
         "47",
         "15",
         "0"
        ],
        [
         "48",
         "17",
         "0"
        ],
        [
         "49",
         "29",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 23113
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_num</th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29c01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>973pb1122c01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23109</th>\n",
       "      <td>satchel4</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23110</th>\n",
       "      <td>973pb1144c01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23111</th>\n",
       "      <td>973pb1145c01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23112</th>\n",
       "      <td>973pb1146c01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           part_num  community\n",
       "0             29c01          0\n",
       "1             3001a          0\n",
       "2             3002a          0\n",
       "3              3003          0\n",
       "4              3004          0\n",
       "...             ...        ...\n",
       "23108  973pb1122c01          0\n",
       "23109      satchel4        202\n",
       "23110  973pb1144c01          0\n",
       "23111  973pb1145c01          0\n",
       "23112  973pb1146c01          0\n",
       "\n",
       "[23113 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node2Vec + K-means\n",
    "embeddings = get_node2vec_embeddings(part_graph)\n",
    "embedding_matrix = np.array([embeddings[part] for part in part_graph.nodes])\n",
    "part_nodes = list(part_graph.nodes)\n",
    "k = 10\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(embedding_matrix)\n",
    "kmeans_communities = pd.DataFrame({\n",
    "    'part_num': part_nodes,\n",
    "    'kmeans_cluster': kmeans_labels\n",
    "})\n",
    "print(\"\\nK-means Clusters:\")\n",
    "print(kmeans_communities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering\n",
    "n_clusters = 10\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=42)\n",
    "adj_matrix = nx.to_numpy_array(part_graph, weight='weight')\n",
    "spectral_labels = spectral.fit_predict(adj_matrix)\n",
    "spectral_communities = pd.DataFrame({\n",
    "    'part_num': part_nodes,\n",
    "    'spectral_cluster': spectral_labels\n",
    "})\n",
    "print(\"\\nSpectral Clusters:\")\n",
    "print(spectral_communities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da601d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Predict Parts for a Theme\n",
    "def predict_parts_global(theme_id, set_parts, communities_df, method='louvain'):\n",
    "    theme_sets = sets[sets['theme_id'] == theme_id]['set_num']\n",
    "    theme_parts = set_parts[set_parts['set_num'].isin(theme_sets)]['part_num'].unique()\n",
    "    \n",
    "    community_col = 'community' if method == 'louvain' else 'kmeans_cluster' if method == 'kmeans' else 'spectral_cluster'\n",
    "    theme_communities = communities_df[communities_df['part_num'].isin(theme_parts)][community_col]\n",
    "    \n",
    "    top_communities = Counter(theme_communities).most_common(3)\n",
    "    top_community_ids = [comm for comm, _ in top_communities]\n",
    "    \n",
    "    predicted_parts = communities_df[communities_df[community_col].isin(top_community_ids)]['part_num'].tolist()\n",
    "    return predicted_parts\n",
    "\n",
    "# Step 5: Evaluate Predictions\n",
    "def evaluate_predictions(theme_id, set_parts, communities_df, method='louvain'):\n",
    "    theme_sets = sets[sets['theme_id'] == theme_id]['set_num']\n",
    "    true_parts = set_parts[set_parts['set_num'].isin(theme_sets)]['part_num'].unique()\n",
    "    predicted_parts = predict_parts_global(theme_id, set_parts, communities_df, method)\n",
    "    \n",
    "    all_parts = set_parts['part_num'].unique()\n",
    "    y_true = [1 if part in true_parts else 0 for part in all_parts]\n",
    "    y_pred = [1 if part in predicted_parts else 0 for part in all_parts]\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Baseline: Most frequent parts\n",
    "def baseline_predict(theme_id, set_parts, top_n=100):\n",
    "    theme_sets = sets[sets['theme_id'] == theme_id]['set_num']\n",
    "    theme_parts = set_parts[set_parts['set_num'].isin(theme_sets)]\n",
    "    top_parts = theme_parts['part_num'].value_counts().head(top_n).index.tolist()\n",
    "    return top_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate Global Approach\n",
    "theme_id = 1  # Replace with valid theme_id\n",
    "results = []\n",
    "\n",
    "# Global Part Graph\n",
    "global_communities = {\n",
    "    'louvain': part_communities,\n",
    "    'kmeans': kmeans_communities,\n",
    "    'spectral': spectral_communities\n",
    "}\n",
    "for method in ['louvain', 'kmeans', 'spectral']:\n",
    "    if not global_communities[method].empty:\n",
    "        metrics = evaluate_predictions(theme_id, set_parts, global_communities[method], method)\n",
    "        results.append({\n",
    "            'Approach': 'Global',\n",
    "            'Method': method.capitalize(),\n",
    "            'Precision': metrics['precision'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'F1': metrics['f1']\n",
    "        })\n",
    "\n",
    "# Baseline\n",
    "baseline_parts = baseline_predict(theme_id, set_parts)\n",
    "y_true = [1 if part in set_parts[set_parts['set_num'].isin(sets[sets['theme_id'] == theme_id]['set_num'])]['part_num'].unique() else 0 for part in set_parts['part_num'].unique()]\n",
    "y_pred_baseline = [1 if part in baseline_parts else 0 for part in set_parts['part_num'].unique()]\n",
    "baseline_metrics = {\n",
    "    'precision': precision_score(y_true, y_pred_baseline, zero_division=0),\n",
    "    'recall': recall_score(y_true, y_pred_baseline, zero_division=0),\n",
    "    'f1': f1_score(y_true, y_pred_baseline, zero_division=0)\n",
    "}\n",
    "results.append({\n",
    "    'Approach': 'Baseline',\n",
    "    'Method': 'Most Frequent',\n",
    "    'Precision': baseline_metrics['precision'],\n",
    "    'Recall': baseline_metrics['recall'],\n",
    "    'F1': baseline_metrics['f1']\n",
    "})\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nGlobal Approach Results:\")\n",
    "print(results_df.to_string(index=False, float_format=\"{:.3f}\".format))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advace_data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
